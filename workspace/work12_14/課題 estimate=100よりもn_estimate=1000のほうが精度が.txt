課題　estimate=100よりもn_estimate=1000のほうが精度が低くなる
たまたま良い決定機が100に集まっているだけ？
↓
バリデーションのrandom_stateを変更してみよう
　estimate=100

random_state=2022
[0.3661, 0.3801, 0.3657, 0.3729, 0.3778] f1_score 0.37252
分散　3.464160000000001e-05
random_state=2021
[0.3555, 0.3676, 0.3618, 0.3985, 0.3749] f1_score 0.37166
分散0.00022114640000000033
label2に関してはn_estimate=1000より40こほど正解が増えている
 estimate=1000
 random_state=2022
[0.3369, 0.3611, 0.3474, 0.3451, 0.3512] f1_score 0.34834
6.265039999999998e-05

[0.3504, 0.3454, 0.3563, 0.3466, 0.3404] f1_score 0.34782
2.819360000000007e-05

決定機が多いので分散が小さく出ると思いきや逆に分散が大きい
↓
どうゆうことが言える？

estimate増やすとpredict=2の個数が大きく減る 具体的には２のラベル総数の半分に
０のラベルが増えるが正解ではない
predict=1が大きく増えてしまう

ほかに気づいたこと
problemsを分解して特徴量を作成していたがproblemsをtargetencodingから外すとなぜか精度が大きく落ちていた
理由は欠損していたから
