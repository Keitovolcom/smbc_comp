課題　estimate=100よりもn_estimate=1000のほうが精度が低くなる
たまたま良い決定機が100に集まっているだけ？
↓
バリデーションのrandom_stateを変更してみよう
　estimate=100

random_state=2022
[0.3661, 0.3801, 0.3657, 0.3729, 0.3778] f1_score 0.37252
分散　3.464160000000001e-05
random_state=2021
[0.3555, 0.3676, 0.3618, 0.3985, 0.3749] f1_score 0.37166
分散0.00022114640000000033
label2に関してはn_estimate=1000より40こほど正解が増えている
 estimate=1000
 random_state=2022
[0.3369, 0.3611, 0.3474, 0.3451, 0.3512] f1_score 0.34834
6.265039999999998e-05

[0.3504, 0.3454, 0.3563, 0.3466, 0.3404] f1_score 0.34782
2.819360000000007e-05

決定機が多いので分散が小さく出ると思いきや逆に分散が大きい
↓
どうゆうことが言える？
もしかしたら訓練データに過学習を起こしているのではないか　→検証データに対して性能が悪いから　→　よってバリデーションの方法がよくないのではないか？
n_estimatorを増やすとdayデータのgain値が大きくなっている　→　dayの重要度が増している。このdayが悪さをしているのではないか？



estimate増やすとpredict=2の個数が大きく減る 具体的には２の正解ラベル総数の半分に
０のラベルが増えるが正解ではない（2,1）に入ってしまう。
predict=1が大きく増えてしまう。


------------validationについて----------
特定の日にちのみ件数が高くなる傾向がある
おそらく休日かな？　→実際に休日が多くなるとは確認できなかった
user_typeごとも観てみたがvolunteerは平日にも活動しており休日に増えるわけではない
そして職員たちの休日のデータ数は平日と比べて低いことが確認することができた。


ほかに気づいたこと
problemsを分解して特徴量を作成していたがproblemsをtargetencodingから外すとなぜか精度が大きく落ちていた
分解した特徴量に欠損していた情報を含まなくなってしまったから
理由は欠損していたから

user_typeによってデータの不出来はなさそう
　　↓
公園専属のスタッフとほぼ同じ正確さで樹木のマッピングを行った（正確さ96％）。


